\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2024


% ready for submission
\usepackage[preprint]{scribe}


% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2024}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2024}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2024}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}	%image
\usepackage{amsmath}	%align
\usepackage{tikz}
\usepackage[fleqn,tbtags]{mathtools}

\input{zsupport/algo}
\input{zsupport/english}
\input{zsupport/figure}
\input{zsupport/linking}
\input{zsupport/math}
\input{zsupport/mathenv}
\input{zsupport/mathvar}
\input{zsupport/refer}
\input{zsupport/table}
\input{zsupport/misc}

% https://www.overleaf.com/learn/latex/Questions/How_do_I_add_additional_author_names_and_affiliations_to_my_paper%3F
\usepackage{authblk}

\usepackage[yyyymmdd,hhmmss]{datetime}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Week 2: Brief Review on Error Function}

\author[1]{Dimas Tri Kurniawan}
\author[2]{Mikhael Deo Barli}
\author[3]{Student3}
\author[4]{Student4}
\affil[1]{2006530261}
\affil[2]{1906350572}
\affil[3]{NPM3}
\affil[4]{NPM4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\maketitle


\section{Understanding, Evaluating, and Improving Performance}


\subsection{Introduction}

Pertama, kita akan mendefinisikan sebuah error function \(E( \hat{y},y)\), baik klasifikasi maupun regresi. Error function membandingkan prediksi \(\hat{y}\) terhadap actual data \(y\) dan akan mengembalikan sebuah nilai yang mengatakan seberapa bagus \(\hat{y}\) untuk memprediksi \(y\) (nol jika sempurna dan sebaliknya). Umumnya, error function untuk klasifikasi maupun regresi adalah sebagai berikut:

Misclassification: $E( \hat{y},y) \coloneq \mathbb{I} \{\hat{y} \neq y\} =$
$\begin{cases}$
0 if $\hat{y}=y \\$
1 if $\hat{y} \neq y \\
\end{cases}$

Squarred error : $E( \hat{y},y) \coloneq \mathbb{I} (\hat{y} \neq y)^2 $ \newline

Walaupun $E( \hat{y},y)$ dan $L( \hat{y},y)$ punya beberapa persamaan, tetapi keduanya berbeda. Loss function $L(\hat{y},y)$ digunakan pada saat learning/training, sedangkan error function $E( \hat{y},y)$ kita gunakan untuk menganalisis performa dari model yang telah menyelesaikan proses training. Pembahasan ke depan akan lebih banyak menyangkut tentang error function dibandingkan dengan loss function. Terdapat 2 error function yang akan dibahas, yaitu empirical risk dan expected risk.

\subsection{Expected New Data Error}

Apapun method klasifikasi maupun regresi yang kita gunakan, selama method tersebut telah belajar berdasarkan training data $ \tau=\{\mathbf{x_i},y_i\}^{n}_{i=1}$, method tersebut akan memberikan prediksi $\hat{y}(\mathbf{x})$ untuk input baru $\mathbf{x}$ yang kita berikan. Karena hal tersebut, kita dapat menulis $\hat{y}(\mathbf{x};\tau)$ untuk menegaskan bahwa model bergantung pada training data $\tau$.

Ketika berbicara mengenai model, biasanya apa yang kita pikirkan pertama kali mengenai model yaitu sesuatu yang memprediksi output untuk satu, beberapa, atau suatu test input $\mathbf{x}$. Sekarang, kita akan membahas mengenai expected new data error $E_{new}$, yaitu integral dari error function terhadap semua kemungkinan data test with respect to distribusi $p(x,y)$: \newline

$E_{new} \coloneq E_*[E(\hat{y}(\mathbf{x};\tau),y)]$, \newline

di mana expectation $E_{new}$ merupakan expectation dari semua kemungkinan data test with respect to distribusi $(\mathbf{x},y) ~ p(\mathbf{x},y)$: \newline

$E_{*}[E(\hat{y}(\mathbf{x};\tau),y)] \coloneq \int E(\hat{y}(\mathbf{x};\tau),y) p(\mathbf{x},y) d\mathbf{x}dy$.

\subsection{Empirical risk}
Empirical risk/training error adalah sebuah estimasi yang bias untuk expected risk. Training error didefinisikan

$E_{train}\coloneq \dfrac{1}{n} \sum^{n}_{i=1} E( \hat{y}(x_i;\tau),yi) $.

$E_train$ mendeskripsikan seberapa bagus sebuah method bekerja pada suatu data yang digunakan untuk training, tetapi error function tersebut tidak memberikan informasi apapun tentang bagaimana performa dari method jika digunakan pada data baru yang tidak di lihat pada training (unseen data).


\subsection{Estimating $E_{new}$}

$E_{new}$ cukup penting untuk dipelajari karena punya beberapa kegunaan:
\begin{itemize}
  \item untuk mengetahui jika performa model cukup bagus;
  \item memilih beberapa method berbeda yang pas;
  \item memilih hyperparamater yang cocok untuk meminimalkan $E_{new}$
  \item melaporkan expected performance ke customer.
\end{itemize}

Namun, terdapat masalah yaitu kita tidak dapat estimate $E_{new}$ dari training data. Kita tidak bisa menggunakan training data secara langsung untuk mengaproksimasi integral pada $E_{train }$, karena artinya kita akan training data 2 kali: pertama, untuk melatih model $\hat{y}(\mathbf{x};\tau)$ dan kedua, untuk mengevaluasi error function pada $E_{train}$. Sederhananya, apakah kita dapat berekpektasi jika method akan bekerja dengan bagus jika dihadapkan dengan data baru yang belum pernah dilihat sama sekali pada proses training? Tentu saja jawabannya tidak.

Untuk itu, kita perlu estimate $E_{new}$ dengan cara yang baru. Solusinya yaitu dengan menggunakan $E_{hold_out}$. Caranya dengan memisahkan beberapa data $\{\mathbf{x}^`_j,y^`_j\}^{n_v}_{j=1}$ (kita sebut dengan \textit{hold-out validation data}) dari $\tau$, yaitu data yang digunakan pada proses training. Lalu, gunakan data tersebut hanya untuk estimate performa model yang bisa kita sebut \textit{hold-out validation error}: \newline

$E_{hold_out} \coloneq \dfrac{1}{n_v} \sum^{n_v}_{j=1} E( \hat{y}(x^`_j;\tau),y^`_j)$. \newline

Dengan demikian, tidak semua data digunakan untuk training, tetapi beberapa ada yang digunakan untuk menghitung $E_{hold-out}$. Agar lebih mudah, prosedur tersebut dapat diilustrasikan melalui gambar di bawah ini:

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{fig/hold_out_val_data.png}
    \caption{Pembagian data training dan hold-out}
    \label{fig:hold_out_val_data}
\end{figure}


\end{document}